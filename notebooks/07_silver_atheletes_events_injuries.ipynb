{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfr5FYngScRb7TwsvUgbPd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasreis95/world-surf-league-data/blob/main/notebooks/07_silver_atheletes_events_injuries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas_gbq\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "metadata": {
        "id": "khB5GjPIOPFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read df from gbq\n",
        "df_raw = pandas_gbq.read_gbq(\n",
        "                             query_or_table = 'wsl-data-397017.01_bronze.wsl_ranking_scrap'\n",
        "                             )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jqt9w81Wtor",
        "outputId": "390c5042-36ce-4e40-879f-d57f4b749a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_rank = df_raw.copy()\n",
        "df_rank = df_rank.sort_values(by = 'index')\n",
        "df_rank = df_rank[['name',\n",
        "                   '1_artboard',\n",
        "                   '2_artboard',\n",
        "                   '3_artboard',\n",
        "                   '4_artboard',\n",
        "                   '5_artboard',\n",
        "                   '6_artboard',\n",
        "                   '7_artboard',\n",
        "                   '8_artboard',\n",
        "                   '9_artboard',\n",
        "                   '10_artboard',\n",
        "                   '11_artboard',\n",
        "                   'year'\n",
        "                   ]]\n",
        "# filter out rows containing cutoff (this just happen on 2022 rank)\n",
        "df_rank = df_rank[~df_rank['name'].isin(['Final 5 Cutoff', 'Cut Line', 'WSL Final 5 Cutoff', 'Mid-Season Cut Line'])]"
      ],
      "metadata": {
        "id": "v7xnOwyRXVHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2MxJD3eN9UH",
        "outputId": "a88172f3-4ae5-48ef-d3ca-9ed8248c1b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2010 injuried df was added.\n",
            "2011 injuried df was added.\n",
            "2012 injuried df was added.\n",
            "2013 injuried df was added.\n",
            "2014 injuried df was added.\n",
            "2015 injuried df was added.\n",
            "2016 injuried df was added.\n",
            "2017 injuried df was added.\n",
            "2018 injuried df was added.\n",
            "2019 injuried df was added.\n",
            "2021 injuried df was added.\n",
            "2022 injuried df was added.\n",
            "2023 injuried df was added.\n",
            "2024 injuried df was added.\n"
          ]
        }
      ],
      "source": [
        "# skip 2020 in year list as we dont't had contest\n",
        "year_list = [i for i in range(2010, 2025) if i != 2020]\n",
        "# get injuried df\n",
        "df_inj_list = []\n",
        "for year in year_list:\n",
        "  df_inj_raw = df_rank[df_rank['year'] == str(year)].copy()\n",
        "  df_inj_raw = df_inj_raw.replace('-',None)\n",
        "  df_inj_raw = df_inj_raw.replace('nan',None)\n",
        "  # count how many empty columns this df has\n",
        "  # that means events that doesn't happened, in some year we had 11 events, while in some, we had just 7\n",
        "  try:\n",
        "    empty_columns = df_inj_raw.isnull().all().value_counts()[True]\n",
        "  except:\n",
        "    empty_columns = 0\n",
        "  # 5 is the number of static columns (name, country, year, rank, total_points)\n",
        "  n_events_on_year = 11 - empty_columns\n",
        "  # repeat df 11 times (numbers of events on this year)\n",
        "  df_inj_raw_to_aux = df_inj_raw.copy()\n",
        "  df_inj_raw = pd.DataFrame(np.repeat(df_inj_raw.values, n_events_on_year, axis=0))\n",
        "  df_inj_raw.columns = df_inj_raw_to_aux.columns\n",
        "  # create aux column\n",
        "  df_inj_raw['aux_column'] = 1\n",
        "  # set every row and a event order\n",
        "  df_inj_raw['event_order'] = df_inj_raw.groupby('name')['aux_column'].transform(pd.Series.cumsum)\n",
        "  df_inj_raw = df_inj_raw.drop(columns = 'aux_column')\n",
        "  # convert year to string\n",
        "  year_str = str(year)\n",
        "  # make request\n",
        "  r = requests.get('https://www.worldsurfleague.com/athletes/tour/mct?year=' + year_str).text\n",
        "  soup = BeautifulSoup(r, 'html.parser')\n",
        "  # get all event places and infos\n",
        "  l = soup.find_all('td', attrs = {'class':'athlete-event-place'})\n",
        "  # convert elements inside list to str\n",
        "  l = [str(i) for i in l]\n",
        "  # keep just events that already happened\n",
        "  l = [s for s in l if s != '<td class=\"athlete-event-place\"><span class=\"tooltip-item\">-</span></td>']\n",
        "  # hard code remove injury duplicated registers\n",
        "  l = [s for s in l if s != '<td class=\"athlete-event-place\"><span class=\"tooltip-item out out\" data-tooltip=\\'{\"content\":\"&lt;strong class=\\\\\"tooltip-contents\\\\\"&gt;&lt;span class=\\\\\"tooltip-inj\\\\\"&gt;INJ&lt;\\\\/span&gt; &lt;span class=\\\\\"status-note\\\\\"&gt;Injured: Ongoing Injury - Replaced by Brodi Sale&lt;\\\\/span&gt;&lt;\\\\/strong&gt;\"}\\'>-</span></td>']\n",
        "  #l = [s for s in l if 'Ongoing Injury' not in s]\n",
        "  # keep just pointing events or previus events that surfer don't came\n",
        "  #l = [x for x in l if 'Points' in x or 'no-count' in x]\n",
        "  # create and aux colummn with raw athlete event place info\n",
        "  df_inj_raw['aux_athl_event_place'] = l\n",
        "  # filter where contains Replaced or Injured\n",
        "  df_inj_raw = df_inj_raw[df_inj_raw['aux_athl_event_place'].str.contains('Replaced|Injured|Withdrawn')]\n",
        "  # select just relevant columns\n",
        "  df_inj_raw = df_inj_raw[['name', 'year', 'event_order']]\n",
        "  # append to main list\n",
        "  df_inj_list.append(df_inj_raw)\n",
        "  # print process has finished\n",
        "  print(year, 'injuried df was added.')\n",
        "# concat all years dfs\n",
        "df_inj = pd.concat(df_inj_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean\n",
        "\n",
        "# remove () from names\n",
        "df_inj['name'] = df_inj['name'].str.replace(r'\\([^)]*\\)', '', regex=True).str.strip()\n",
        "# replace country names\n",
        "df_inj['name'] = df_inj['name'].str.replace('United States','United_states')\\\n",
        "                       .str.replace('South Africa','South_africa')\\\n",
        "                       .str.replace('New Zealand','New_zealand')\\\n",
        "                       .str.replace('French Polynesia','French_polynesia')\\\n",
        "                       .str.replace('Costa Rica','Costa_rica')\n",
        "\n",
        "# add space before last capital letter, that means before surfer country\n",
        "df_inj['name'] = df_inj['name'].str.replace( r\"([A-Z])\", r\" \\1\", regex=True).str.strip()\n",
        "# split name and country by last space\n",
        "df_inj[['name','athlete_country']] = df_inj['name'].str.rsplit(expand=True, n=1)\n",
        "# drop athlete_country country\n",
        "df_inj = df_inj.drop(columns = 'athlete_country')\n",
        "# lower case and strip names and countries\n",
        "#df_inj['athlete_country'] = df_inj['athlete_country'].str.lower()\n",
        "#df_inj['athlete_country'] = df_inj['athlete_country'].str.replace('_', ' ')\n",
        "df_inj['name'] = df_inj['name'].str.lower()\n",
        "df_inj['name']= df_inj['name'].replace(r'\\s+', ' ', regex=True)\n",
        "# rename columns\n",
        "df_inj = df_inj.rename(columns = {\n",
        "                          'name':'athlete_name',\n",
        "                          'year':'season_year'\n",
        "                          })"
      ],
      "metadata": {
        "id": "e5kiXEYJxPbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write raw table in big query\n",
        "pandas_gbq.to_gbq(\n",
        "                  dataframe = df_inj,\n",
        "                  destination_table = 'wsl-data-397017.02_silver.wsl_atheletes_events_injuries',\n",
        "                  project_id = 'wsl-data-397017',\n",
        "                  if_exists = 'replace'\n",
        "                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg-wRBRHyNIT",
        "outputId": "23807948-e808-464b-a4a8-0c7d7938f5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 8035.07it/s]\n"
          ]
        }
      ]
    }
  ]
}